{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-08T13:31:31.362243600Z",
     "start_time": "2023-08-08T13:31:27.729105900Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from Dive_into_deep_learning.d2l import tensorflow as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class RNNScratch(d2l.Module):\n",
    "    def __init__(self, num_inputs, num_hiddens, sigma=0.01):\n",
    "        \"\"\"\n",
    "        :param num_inputs: num of unique tokens\n",
    "        :param num_hiddens: \n",
    "        :param sigma: \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.W_xh = tf.Variable(tf.random.normal((num_inputs, num_hiddens)) * sigma)\n",
    "        self.W_hh = tf.Variable(tf.random.normal((num_hiddens, num_hiddens)) * sigma)\n",
    "        self.b_h = tf.Variable(tf.zeros(num_hiddens))\n",
    "\n",
    "    def forward(self, inputs, state=None):\n",
    "        if state is None:\n",
    "            # Initial state with shape: (batch_size, nun_hiddens)\n",
    "            state = tf.zeros((inputs.shape[1], self.num_hiddens))\n",
    "        else:\n",
    "            state, = state\n",
    "            state = tf.reshape(state, (-1, self.num_hiddens))\n",
    "        outputs = []\n",
    "        for X in inputs:  # Shape of inputs: (num_steps, batch_size, num_inputs)\n",
    "            state = tf.tanh(tf.matmul(X, self.W_xh) + tf.matmul(state, self.W_hh) + self.b_h)\n",
    "            outputs.append(state)\n",
    "        return outputs, state"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T13:31:33.601854400Z",
     "start_time": "2023-08-08T13:31:33.563499900Z"
    }
   },
   "id": "29dae5fb69fc443c"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "['_SCALAR_UPRANKING_ON',\n '_TF_MODULE_IGNORED_PROPERTIES',\n '__call__',\n '__class__',\n '__copy__',\n '__deepcopy__',\n '__delattr__',\n '__dict__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__getstate__',\n '__gt__',\n '__hash__',\n '__init__',\n '__init_subclass__',\n '__le__',\n '__lt__',\n '__module__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__setstate__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n '__weakref__',\n '_add_trackable',\n '_add_trackable_child',\n '_add_variable_with_custom_getter',\n '_assert_compile_was_called',\n '_assert_weights_created',\n '_autographed_call',\n '_cast_single_input',\n '_check_call_args',\n '_check_sample_weight_warning',\n '_checkpoint_dependencies',\n '_clear_losses',\n '_compile_was_called',\n '_compute_dtype',\n '_configure_steps_per_execution',\n '_dedup_weights',\n '_deferred_dependencies',\n '_delete_tracking',\n '_deserialization_dependencies',\n '_deserialize_from_proto',\n '_dtype',\n '_eager_losses',\n '_expects_mask_arg',\n '_expects_training_arg',\n '_export_to_saved_model_graph',\n '_flatten',\n '_flatten_layers',\n '_flatten_modules',\n '_functional_construction_call',\n '_gather_children_attribute',\n '_gather_saveables_for_checkpoint',\n '_get_callback_model',\n '_get_cell_name',\n '_get_compile_args',\n '_get_existing_metric',\n '_get_input_masks',\n '_get_node_attribute_at_index',\n '_get_optimizer',\n '_get_save_spec',\n '_get_trainable_state',\n '_get_unnested_name_scope',\n '_handle_activity_regularization',\n '_handle_deferred_dependencies',\n '_handle_weight_regularization',\n '_in_multi_worker_mode',\n '_inbound_nodes',\n '_infer_output_signature',\n '_init_batch_counters',\n '_init_call_fn_args',\n '_init_set_name',\n '_instrument_layer_creation',\n '_is_layer',\n '_keras_api_names',\n '_keras_api_names_v1',\n '_keras_tensor_symbolic_call',\n '_lookup_dependency',\n '_map_resources',\n '_maybe_build',\n '_maybe_cast_inputs',\n '_maybe_create_attribute',\n '_maybe_initialize_trackable',\n '_maybe_load_initial_counters_from_ckpt',\n '_maybe_load_initial_step_from_ckpt',\n '_must_restore_from_config',\n '_name_based_attribute_restore',\n '_name_based_restores',\n '_name_scope',\n '_no_dependency',\n '_obj_reference_counts',\n '_object_identifier',\n '_outbound_nodes',\n '_preload_simple_restoration',\n '_reset_compile_cache',\n '_restore_from_tensors',\n '_save_new',\n '_serialize_to_proto',\n '_serialize_to_tensors',\n '_set_connectivity_metadata',\n '_set_dtype_policy',\n '_set_inputs',\n '_set_mask_keras_history_checked',\n '_set_mask_metadata',\n '_set_save_spec',\n '_set_trainable_state',\n '_set_training_mode',\n '_setattr_tracking',\n '_should_cast_single_input',\n '_should_compute_mask',\n '_should_eval',\n '_tf_api_names',\n '_tf_api_names_v1',\n '_track_trackable',\n '_trackable_children',\n '_trackable_saved_model_saver',\n '_tracking_metadata',\n '_unconditional_checkpoint_dependencies',\n '_unconditional_dependency_names',\n '_undeduplicated_weights',\n '_update_uid',\n '_updated_config',\n '_use_input_spec_as_call_signature',\n '_validate_compile',\n '_validate_target_and_loss',\n 'activity_regularizer',\n 'add_loss',\n 'add_metric',\n 'add_update',\n 'add_variable',\n 'add_weight',\n 'build',\n 'call',\n 'compile',\n 'compute_dtype',\n 'compute_loss',\n 'compute_mask',\n 'compute_metrics',\n 'compute_output_shape',\n 'compute_output_signature',\n 'configure_optimizers',\n 'count_params',\n 'distribute_strategy',\n 'dtype',\n 'dtype_policy',\n 'dynamic',\n 'evaluate',\n 'evaluate_generator',\n 'finalize_state',\n 'fit',\n 'fit_generator',\n 'forward',\n 'from_config',\n 'get_config',\n 'get_input_at',\n 'get_input_mask_at',\n 'get_input_shape_at',\n 'get_layer',\n 'get_output_at',\n 'get_output_mask_at',\n 'get_output_shape_at',\n 'get_weight_paths',\n 'get_weights',\n 'inbound_nodes',\n 'input',\n 'input_mask',\n 'input_shape',\n 'input_spec',\n 'layers',\n 'load_weights',\n 'loss',\n 'losses',\n 'make_predict_function',\n 'make_test_function',\n 'make_train_function',\n 'metrics',\n 'metrics_names',\n 'name',\n 'name_scope',\n 'non_trainable_variables',\n 'non_trainable_weights',\n 'outbound_nodes',\n 'output',\n 'output_mask',\n 'output_shape',\n 'plot',\n 'predict',\n 'predict_generator',\n 'predict_on_batch',\n 'predict_step',\n 'reset_metrics',\n 'reset_states',\n 'run_eagerly',\n 'save',\n 'save_hyperparameters',\n 'save_spec',\n 'save_weights',\n 'set_weights',\n 'state_updates',\n 'stateful',\n 'submodules',\n 'summary',\n 'supports_masking',\n 'test_on_batch',\n 'test_step',\n 'to_json',\n 'to_yaml',\n 'train_on_batch',\n 'train_step',\n 'trainable',\n 'trainable_variables',\n 'trainable_weights',\n 'training_step',\n 'updates',\n 'validation_step',\n 'variable_dtype',\n 'variables',\n 'weights',\n 'with_name_scope']"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(RNNScratch)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T13:32:18.325280200Z",
     "start_time": "2023-08-08T13:32:18.221239400Z"
    }
   },
   "id": "38907008b0640114"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "mappingproxy({'__module__': '__main__',\n              '__init__': <function __main__.RNNScratch.__init__(self, num_inputs, num_hiddens, sigma=0.01)>,\n              'forward': <function __main__.RNNScratch.forward(self, inputs, state=None)>,\n              '__doc__': None})"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNNScratch.__dict__"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T13:44:04.230052400Z",
     "start_time": "2023-08-08T13:44:04.152042300Z"
    }
   },
   "id": "9e5edf031ff6fd6a"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "batch_size, num_inputs, num_hiddens, num_steps = 2, 16, 32, 100\n",
    "rnn = RNNScratch(num_inputs, num_hiddens)\n",
    "X = tf.ones((num_steps, batch_size, num_inputs))\n",
    "outputs, state = rnn(X)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-08T13:29:22.140956700Z"
    }
   },
   "id": "c46b153256fcfaff"
  },
  {
   "cell_type": "markdown",
   "source": [
    "outputs保留了所有的state，而state变量保留的是最后一个state"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abec99f0826e1abc"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# np.all((outputs[-1] == state).numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T05:53:36.143132Z",
     "start_time": "2023-08-07T05:53:36.137060Z"
    }
   },
   "id": "8d2c488c82d5ae9d"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def check_len(a, n):  #@save\n",
    "    \"\"\"Check the length of a list.\"\"\"\n",
    "    assert len(a) == n, f'list\\'s length {len(a)} != expected length {n}'\n",
    "\n",
    "def check_shape(a, shape):  #@save\n",
    "    \"\"\"Check the shape of a tensor.\"\"\"\n",
    "    assert a.shape == shape, \\\n",
    "        f'tensor\\'s shape {a.shape} != expected shape {shape}'\n",
    "\n",
    "check_len(outputs, num_steps)\n",
    "check_shape(outputs[0], (batch_size, num_hiddens))\n",
    "check_shape(state, (batch_size, num_hiddens))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T06:14:20.800269Z",
     "start_time": "2023-08-07T06:14:20.786454Z"
    }
   },
   "id": "5e80528973e71381"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "a = tf.Variable(5)\n",
    "b = tf.reshape(a, (-1,))\n",
    "c = tf.reshape(a, ())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T15:40:50.416771500Z",
     "start_time": "2023-08-08T15:40:45.796238500Z"
    }
   },
   "id": "aba611bbc7ebed14"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T15:41:46.911718400Z",
     "start_time": "2023-08-08T15:41:46.795873900Z"
    }
   },
   "id": "ff9b7e85986e5bfd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RNN-based Language Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4389950969280859"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class RNNLMScratch(d2l.Classifier):  #@save\n",
    "    \"\"\"The RNN-based language model implemented from scratch.\"\"\"\n",
    "\n",
    "    def __init__(self, rnn, vocab_size, lr=0.01):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.init_params()\n",
    "\n",
    "    def init_params(self):\n",
    "        self.W_hq = tf.Variable(tf.random.normal(\n",
    "            (self.rnn.num_hiddens, self.vocab_size)) * self.rnn.sigma)\n",
    "        self.b_q = tf.Variable(tf.zeros(self.vocab_size))\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        l = self.loss(self(*batch[:-1]), batch[-1])\n",
    "        self.plot('ppl', tf.exp(l), train=True)\n",
    "        return l\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        l = self.loss(self(*batch[:-1]), batch[-1])\n",
    "        self.plot('ppl', tf.exp(l), train=False)\n",
    "\n",
    "    def one_hot(self, X):\n",
    "        # Output shape: (num_steps, batch_size, vocab_size)\n",
    "        return tf.one_hot(tf.transpose(X), self.vocab_size)\n",
    "    \n",
    "    def output_layer(self, rnn_outputs):\n",
    "        outputs = [tf.matmul(H, self.W_hq) + self.b_q for H in rnn_outputs]\n",
    "        return tf.stack(outputs, 1)\n",
    "    \n",
    "    def forward(self, X, state=None):\n",
    "        embs = self.one_hot(X)\n",
    "        rnn_outputs, _ = self.rnn(embs, state)\n",
    "        return self.output_layer(rnn_outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T05:53:36.160091Z",
     "start_time": "2023-08-07T05:53:36.150549Z"
    }
   },
   "id": "3b8127f18728fce8"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "model = RNNLMScratch(rnn, num_inputs)\n",
    "outputs = model(tf.ones((batch_size, num_steps), dtype=tf.int64))\n",
    "check_shape(outputs, (batch_size, num_steps, num_inputs))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T05:53:36.160565Z",
     "start_time": "2023-08-07T05:53:36.154126Z"
    }
   },
   "id": "207fe8a476cc4516"
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "@d2l.add_to_class(d2l.Trainer)\n",
    "def clip_gradients(self, grad_clip_val, grads):\n",
    "    grad_clip_val = tf.constant(grad_clip_val, dtype=tf.float32)\n",
    "    new_grads = [tf.convert_to_tensor(grad) if isinstance(grad, tf.IndexedSlices) else grad for grad in grads]\n",
    "    norm = tf.math.sqrt(sum((tf.reduce_sum(grad ** 2)) for grad in new_grads))\n",
    "    if tf.greater(norm, grad_clip_val):\n",
    "        for i, grad in enumerate(new_grads):\n",
    "            new_grads[i] = grad * grad_clip_val / norm\n",
    "        return new_grads\n",
    "    return grads"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46969460605fc1a4"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 17\u001B[0m\n\u001B[1;32m     15\u001B[0m     model \u001B[38;5;241m=\u001B[39m RNNLMScratch(rnn, vocab_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(data\u001B[38;5;241m.\u001B[39mvocab), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     16\u001B[0m trainer \u001B[38;5;241m=\u001B[39m d2l\u001B[38;5;241m.\u001B[39mTrainer(max_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, gradient_clip_val\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 17\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/DataspellProjects/Machine-Learning/Dive_into_deep_learning/d2l/tensorflow.py:264\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[0;34m(self, model, data)\u001B[0m\n\u001B[1;32m    262\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mval_batch_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    263\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mepoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_epochs):\n\u001B[0;32m--> 264\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/DataspellProjects/Machine-Learning/Dive_into_deep_learning/d2l/tensorflow.py:278\u001B[0m, in \u001B[0;36mTrainer.fit_epoch\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    276\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_dataloader:\n\u001B[1;32m    277\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mGradientTape() \u001B[38;5;28;01mas\u001B[39;00m tape:\n\u001B[0;32m--> 278\u001B[0m         loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_step\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprepare_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    279\u001B[0m     grads \u001B[38;5;241m=\u001B[39m tape\u001B[38;5;241m.\u001B[39mgradient(loss, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mtrainable_variables)\n\u001B[1;32m    280\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgradient_clip_val \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "Cell \u001B[0;32mIn[5], line 15\u001B[0m, in \u001B[0;36mRNNLMScratch.training_step\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtraining_step\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch):\n\u001B[0;32m---> 15\u001B[0m     l \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss(\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m, batch[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mplot(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mppl\u001B[39m\u001B[38;5;124m'\u001B[39m, tf\u001B[38;5;241m.\u001B[39mexp(l), train\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m l\n",
      "File \u001B[0;32m~/miniconda3/envs/tensorflow_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/miniconda3/envs/tensorflow_env/lib/python3.10/site-packages/keras/engine/training.py:557\u001B[0m, in \u001B[0;36mModel.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    553\u001B[0m         \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(inputs, \u001B[38;5;241m*\u001B[39mcopied_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcopied_kwargs)\n\u001B[1;32m    555\u001B[0m     layout_map_lib\u001B[38;5;241m.\u001B[39m_map_subclass_model_variable(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_layout_map)\n\u001B[0;32m--> 557\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/tensorflow_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/miniconda3/envs/tensorflow_env/lib/python3.10/site-packages/keras/engine/base_layer.py:1097\u001B[0m, in \u001B[0;36mLayer.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1092\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_cast_inputs(inputs, input_list)\n\u001B[1;32m   1094\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m autocast_variable\u001B[38;5;241m.\u001B[39menable_auto_cast_variables(\n\u001B[1;32m   1095\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compute_dtype_object\n\u001B[1;32m   1096\u001B[0m ):\n\u001B[0;32m-> 1097\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mcall_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_activity_regularizer:\n\u001B[1;32m   1100\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001B[0;32m~/miniconda3/envs/tensorflow_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py:96\u001B[0m, in \u001B[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     94\u001B[0m bound_signature \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     95\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     97\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     98\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_keras_call_info_injected\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m     99\u001B[0m         \u001B[38;5;66;03m# Only inject info for the innermost failing call\u001B[39;00m\n",
      "File \u001B[0;32m~/DataspellProjects/Machine-Learning/Dive_into_deep_learning/d2l/tensorflow.py:181\u001B[0m, in \u001B[0;36mModule.call\u001B[0;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[1;32m    180\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 181\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mkwargs\u001B[49m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtraining\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m kwargs:\n\u001B[1;32m    182\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtraining\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m    183\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward(X, \u001B[38;5;241m*\u001B[39margs)\n",
      "File \u001B[0;32m~/DataspellProjects/Machine-Learning/Dive_into_deep_learning/d2l/tensorflow.py:181\u001B[0m, in \u001B[0;36mModule.call\u001B[0;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[1;32m    180\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 181\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mkwargs\u001B[49m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtraining\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m kwargs:\n\u001B[1;32m    182\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtraining\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m    183\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward(X, \u001B[38;5;241m*\u001B[39margs)\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:1179\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.SafeCallWrapper.__call__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:620\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:1095\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:1057\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:317\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.PyDBFrame.do_wait_suspend\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/Applications/DataSpell.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py:1160\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1157\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[1;32m   1159\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[0;32m-> 1160\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Applications/DataSpell.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py:1175\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1172\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[1;32m   1174\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[0;32m-> 1175\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1177\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[1;32m   1179\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "data = d2l.TimeMachine(batch_size=1024, num_steps=32)\n",
    "with d2l.try_gpu():\n",
    "    rnn = RNNScratch(num_inputs=len(data.vocab), num_hiddens=32)\n",
    "    model = RNNLMScratch(rnn, vocab_size=len(data.vocab), lr=1)\n",
    "trainer = d2l.Trainer(max_epochs=100, gradient_clip_val=1)\n",
    "trainer.fit(model, data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-07T06:44:29.579684Z"
    }
   },
   "id": "adce48a5f820a612"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "'it has of the the the the '"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@d2l.add_to_class(RNNLMScratch)  #@save\n",
    "def predict(self, prefix, num_preds, vocab, device=None):\n",
    "    state, outputs = None, [vocab[prefix[0]]]\n",
    "    for i in range(len(prefix) + num_preds - 1):\n",
    "        X = tf.constant([[outputs[-1]]])  # 得到前缀的第0个字符对应的整数编码，封装成二维tensor\n",
    "        embs = self.one_hot(X)\n",
    "        rnn_outputs, state = self.rnn(embs, state)\n",
    "        if i < len(prefix) - 1:  # Warm-up period\n",
    "            outputs.append(vocab[prefix[i + 1]])\n",
    "        else:  # Predict num_preds steps\n",
    "            Y = self.output_layer(rnn_outputs)\n",
    "            outputs.append(int(tf.reshape(tf.argmax(Y, axis=2), 1)))\n",
    "    return ''.join([vocab.idx_to_token[i] for i in outputs])\n",
    "\n",
    "model.predict('it has', 20, data.vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T05:43:03.116699Z",
     "start_time": "2023-08-07T05:43:03.069467Z"
    }
   },
   "id": "c6bf756ca44abf9a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "assert ('linux' in sys.platform), \"该代码只能在 Linux 下执行\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25a42c3c0fabcb53"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
