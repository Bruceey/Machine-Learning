{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-05T01:28:28.666801Z",
     "start_time": "2023-08-05T01:28:22.124456Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-05 09:28:22.247556: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from Dive_into_deep_learning.d2l import tensorflow as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "@d2l.add_to_class(d2l.TimeMachine)\n",
    "def __init__(self, batch_size, num_steps, num_train=10000, num_val=5000):\n",
    "    super(d2l.TimeMachine, self).__init__()\n",
    "    self.save_hyperparameters()\n",
    "    corpus, self.vocab = self.build(self._download()) # corpus是token的整数表示\n",
    "    array = tf.constant([corpus[i: i + num_steps + 1]\n",
    "                         for i in range(len(corpus) - num_steps)])\n",
    "    self.X, self.Y = array[:, :-1], array[:, 1:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-05T01:28:28.680606Z",
     "start_time": "2023-08-05T01:28:28.669205Z"
    }
   },
   "id": "36e0e15e23c91ce3"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "@d2l.add_to_class(d2l.TimeMachine)\n",
    "def get_dataloader(self, train):\n",
    "    idx = slice(0, self.num_train) if train else slice(self.num_train, self.num_train + self.num_val)\n",
    "    return self.get_tensorloader([self.X, self.Y], train, idx)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-05T01:28:28.681050Z",
     "start_time": "2023-08-05T01:28:28.675057Z"
    }
   },
   "id": "a9c051b36c076740"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tf.Tensor(\n",
      "[[22 15  8  0 14  2 15  0 21  9]\n",
      " [ 6  2 19 26  0 13  6 21  0 20]], shape=(2, 10), dtype=int32) \n",
      "Y: tf.Tensor(\n",
      "[[15  8  0 14  2 15  0 21  9 16]\n",
      " [ 2 19 26  0 13  6 21  0 20  0]], shape=(2, 10), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-05 09:28:28.958322: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "data = d2l.TimeMachine(batch_size=2, num_steps=10)\n",
    "for X, Y in data.train_dataloader():\n",
    "    print('X:', X, '\\nY:', Y)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-05T01:28:29.160012Z",
     "start_time": "2023-08-05T01:28:28.681832Z"
    }
   },
   "id": "8e853ad8e9f7b9d1"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "28"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.vocab.__len__()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-05T01:28:29.164085Z",
     "start_time": "2023-08-05T01:28:29.155212Z"
    }
   },
   "id": "8015f4b32c66a356"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-05T01:28:29.164993Z",
     "start_time": "2023-08-05T01:28:29.160453Z"
    }
   },
   "id": "1046d71680d42923"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 中文版对应内容"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "881934dcc95df955"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def seq_data_iter_random(corpus, batch_size, num_steps):  #@save\n",
    "    \"\"\"使用随机抽样生成一个小批量子序列\"\"\"\n",
    "    # 从随机偏移量开始对序列进行分区，随机范围包括num_steps-1\n",
    "    corpus = corpus[random.randint(0, num_steps - 1):]\n",
    "    # 减去1，是因为我们需要考虑标签\n",
    "    num_subseqs = (len(corpus) - 1) // num_steps\n",
    "    # 长度为num_steps的子序列的起始索引\n",
    "    initial_indices = list(range(0, num_subseqs * num_steps, num_steps))\n",
    "    # 在随机抽样的迭代过程中，\n",
    "    # 来自两个相邻的、随机的、小批量中的子序列不一定在原始序列上相邻\n",
    "    random.shuffle(initial_indices)\n",
    "\n",
    "    def data(pos):\n",
    "        # 返回从pos位置开始的长度为num_steps的序列\n",
    "        return corpus[pos: pos + num_steps]\n",
    "\n",
    "    num_batches = num_subseqs // batch_size\n",
    "    for i in range(0, batch_size * num_batches, batch_size):\n",
    "        # 在这里，initial_indices包含子序列的随机起始索引\n",
    "        initial_indices_per_batch = initial_indices[i: i + batch_size]\n",
    "        X = [data(j) for j in initial_indices_per_batch]\n",
    "        Y = [data(j + 1) for j in initial_indices_per_batch]\n",
    "        yield tf.constant(X), tf.constant(Y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-05T01:28:29.177161Z",
     "start_time": "2023-08-05T01:28:29.166267Z"
    }
   },
   "id": "7116cc5207dc7bc5"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  tf.Tensor(\n",
      "[[11 12 13 14 15]\n",
      " [16 17 18 19 20]], shape=(2, 5), dtype=int32) \n",
      "Y: tf.Tensor(\n",
      "[[12 13 14 15 16]\n",
      " [17 18 19 20 21]], shape=(2, 5), dtype=int32)\n",
      "X:  tf.Tensor(\n",
      "[[ 6  7  8  9 10]\n",
      " [21 22 23 24 25]], shape=(2, 5), dtype=int32) \n",
      "Y: tf.Tensor(\n",
      "[[ 7  8  9 10 11]\n",
      " [22 23 24 25 26]], shape=(2, 5), dtype=int32)\n",
      "X:  tf.Tensor(\n",
      "[[26 27 28 29 30]\n",
      " [ 1  2  3  4  5]], shape=(2, 5), dtype=int32) \n",
      "Y: tf.Tensor(\n",
      "[[27 28 29 30 31]\n",
      " [ 2  3  4  5  6]], shape=(2, 5), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "my_seq = list(range(35))\n",
    "for X, Y in seq_data_iter_random(my_seq, batch_size=2, num_steps=5):\n",
    "    print('X: ', X, '\\nY:', Y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-05T01:28:29.224832Z",
     "start_time": "2023-08-05T01:28:29.171855Z"
    }
   },
   "id": "906e1123ea83967"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def seq_data_iter_sequential(corpus, batch_size, num_steps):  #@save\n",
    "    \"\"\"使用顺序分区生成一个小批量子序列\"\"\"\n",
    "    # 从随机偏移量开始划分序列\n",
    "    offset = random.randint(0, num_steps)\n",
    "    num_tokens = ((len(corpus) - offset - 1) // batch_size) * batch_size\n",
    "    Xs = tf.constant(corpus[offset: offset + num_tokens])\n",
    "    Ys = tf.constant(corpus[offset + 1: offset + 1 + num_tokens])\n",
    "    Xs = tf.reshape(Xs, (batch_size, -1))\n",
    "    Ys = tf.reshape(Ys, (batch_size, -1))\n",
    "    num_batches = Xs.shape[1] // num_steps\n",
    "    for i in range(0, num_batches * num_steps, num_steps):\n",
    "        X = Xs[:, i: i + num_steps]\n",
    "        Y = Ys[:, i: i + num_steps]\n",
    "        yield X, Y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-05T01:28:29.225628Z",
     "start_time": "2023-08-05T01:28:29.180786Z"
    }
   },
   "id": "d5b75c142ba48a06"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  tf.Tensor(\n",
      "[[ 2  3  4  5  6]\n",
      " [18 19 20 21 22]], shape=(2, 5), dtype=int32) \n",
      "Y: tf.Tensor(\n",
      "[[ 3  4  5  6  7]\n",
      " [19 20 21 22 23]], shape=(2, 5), dtype=int32)\n",
      "X:  tf.Tensor(\n",
      "[[ 7  8  9 10 11]\n",
      " [23 24 25 26 27]], shape=(2, 5), dtype=int32) \n",
      "Y: tf.Tensor(\n",
      "[[ 8  9 10 11 12]\n",
      " [24 25 26 27 28]], shape=(2, 5), dtype=int32)\n",
      "X:  tf.Tensor(\n",
      "[[12 13 14 15 16]\n",
      " [28 29 30 31 32]], shape=(2, 5), dtype=int32) \n",
      "Y: tf.Tensor(\n",
      "[[13 14 15 16 17]\n",
      " [29 30 31 32 33]], shape=(2, 5), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for X, Y in seq_data_iter_sequential(my_seq, batch_size=2, num_steps=5):\n",
    "    print('X: ', X, '\\nY:', Y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-05T01:28:29.240536Z",
     "start_time": "2023-08-05T01:28:29.184443Z"
    }
   },
   "id": "97700a607dd32c57"
  },
  {
   "cell_type": "markdown",
   "source": [
    "注意偏移量减1和不减1的区别"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2232416d9e84f120"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4db427dd74dedbc4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
