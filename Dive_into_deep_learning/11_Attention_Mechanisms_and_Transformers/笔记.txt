new_tensor = matrix.detach()  # 返回和matrix相同的tensor，但该tensor不会参与反向传播

排序：
    x = torch.randn(3, 4)
    sorted, indices = torch.sort(x) # sorted是排序好的tensor，默认按照最后一个轴排序；indices返回sorted值在原tensor中的对应索引


2. plt.subplots(num_rows, num_cols, figsize=figsize, sharex=True, sharey=True, squeeze=False)
squeeze：bool, default: True
If True, extra dimensions are squeezed out from the returned array of Axes:
    if only one subplot is constructed (nrows=ncols=1), the resulting single Axes object is returned as a scalar.
    for Nx1 or 1xM subplots, the returned object is a 1D numpy object array of Axes objects.
    for NxM, subplots with N>1 and M>1 are returned as a 2D array.

If False, no squeezing at all is done:
    the returned Axes object is always a 2D array containing Axes instances, even if it ends up being 1x1.


3. c = b[None, :]    # 表示新增一个维度

4. 重复数据;
   torch.repeat_interleave()
   tf.repeat()

5. torch.permute(input, dims) → Tensor
   Returns a view of the original tensor input with its dimensions permuted.

        >>> x = torch.randn(2, 3, 5)
        >>> x.size()
        torch.Size([2, 3, 5])
        >>> torch.permute(x, (2, 0, 1)).size()
        torch.Size([5, 2, 3])
