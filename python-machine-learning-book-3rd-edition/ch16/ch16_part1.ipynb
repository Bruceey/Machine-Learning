{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-01T05:27:41.150007Z",
     "start_time": "2023-08-01T05:27:40.635026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_xh shape: (5, 2)\n",
      "W_oo shape: (2, 2)\n",
      "b_h shape: (2,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "rnn_layer = tf.keras.layers.SimpleRNN(\n",
    "    units=2, use_bias=True,\n",
    "    return_sequences=True\n",
    ")\n",
    "rnn_layer.build(input_shape=(None, None, 5))\n",
    "\n",
    "w_xh, w_oo, b_h = rnn_layer.weights\n",
    "\n",
    "print('W_xh shape:', w_xh.shape)\n",
    "print('W_oo shape:', w_oo.shape)\n",
    "print('b_h shape:', b_h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 0 =>\n",
      "   Input           : [[1. 1. 1. 1. 1.]]\n",
      "   Hidden          : [[-0.10616481 -0.1218155 ]]\n",
      "   Output (manual) : [[-0.10576773 -0.1212165 ]]\n",
      "   SimpleRNN 0 output: [-0.10576773 -0.1212165 ]\n",
      "\n",
      "Time step 1 =>\n",
      "   Input           : [[2. 2. 2. 2. 2.]]\n",
      "   Hidden          : [[-0.21232963 -0.243631  ]]\n",
      "   Output (manual) : [[-0.34740958 -0.18380591]]\n",
      "   SimpleRNN 1 output: [-0.34740958 -0.18380591]\n",
      "\n",
      "Time step 2 =>\n",
      "   Input           : [[3. 3. 3. 3. 3.]]\n",
      "   Hidden          : [[-0.3184942  -0.36544657]]\n",
      "   Output (manual) : [[-0.5444225  -0.10192319]]\n",
      "   SimpleRNN 2 output: [-0.5444225  -0.10192319]\n"
     ]
    }
   ],
   "source": [
    "x_seq = tf.convert_to_tensor(\n",
    "    [[1.] * 5, [2.] * 5, [3.] * 5],\n",
    "    dtype=tf.float32\n",
    ")\n",
    "\n",
    "output = rnn_layer(tf.reshape(x_seq, shape=(1, 3, 5)))\n",
    "\n",
    "out_man = []\n",
    "for t in range(len(x_seq)):\n",
    "    xt = tf.reshape(x_seq[t], (1, 5))\n",
    "    print(f'Time step {t} =>')\n",
    "    print('   Input           :', xt.numpy())\n",
    "    \n",
    "    ht = tf.matmul(xt, w_xh) + b_h\n",
    "    print('   Hidden          :', ht.numpy())\n",
    "    \n",
    "    if t > 0:\n",
    "        pre_o = out_man[t - 1]\n",
    "    else:\n",
    "        pre_o = tf.zeros(shape=ht.shape)\n",
    "    \n",
    "    ot = ht + tf.matmul(pre_o, w_oo)\n",
    "    ot = tf.math.tanh(ot)\n",
    "    out_man.append(ot)\n",
    "    print('   Output (manual) :', ot.numpy())\n",
    "    print('   SimpleRNN {} output:'.format(t), output[0][t].numpy())\n",
    "    print()\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T01:57:15.867398Z",
     "start_time": "2023-08-01T01:57:15.848805Z"
    }
   },
   "id": "b6344c8d51566f8f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Implementing RNNs for sequence modeling in TensorFlow\n",
    "\n",
    "## Project one: predicting the sentiment of IMDb movie reviews\n",
    "\n",
    "### Preparing the movie review data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82f1a75ea6c03701"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                  review  sentiment\n49995  OK, lets start with the best. the building. al...          0\n49996  The British 'heritage film' industry is out of...          0\n49997  I don't even know where to begin on this one. ...          0\n49998  Richard Tyler is a little boy who is scared of...          0\n49999  I waited long to watch this movie. Also becaus...          1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>49995</th>\n      <td>OK, lets start with the best. the building. al...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>The British 'heritage film' industry is out of...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>I don't even know where to begin on this one. ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>Richard Tyler is a little boy who is scared of...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>I waited long to watch this movie. Also becaus...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../datasets/movie_data.csv', encoding='utf-8')\n",
    "df.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T05:46:12.955480Z",
     "start_time": "2023-08-01T05:46:12.528557Z"
    }
   },
   "id": "1830883105d63b18"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'In 1974, the teenager Martha Moxley (Maggie Grace)' 1\n",
      "b'OK... so... I really like Kris Kristofferson and h' 0\n",
      "b'***SPOILER*** Do not read this, if you think about' 0\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create a dataset\n",
    "\n",
    "ds_raw = tf.data.Dataset.from_tensor_slices((df.review, df.sentiment))\n",
    "\n",
    "## inspection\n",
    "for ex in ds_raw.take(3):\n",
    "    tf.print(ex[0].numpy()[:50], ex[1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T05:46:14.164998Z",
     "start_time": "2023-08-01T05:46:14.140621Z"
    }
   },
   "id": "6403f0a05300cb19"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# Train/validation/test splits\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "ds_raw = ds_raw.shuffle(50000, reshuffle_each_iteration=False)\n",
    "ds_raw_test = ds_raw.take(25000)\n",
    "ds_raw_train_valid = ds_raw.take(25000)\n",
    "ds_raw_train = ds_raw_train_valid.take(20000)\n",
    "ds_raw_valid = ds_raw_train_valid.skip(20000)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T06:29:19.698476Z",
     "start_time": "2023-08-01T06:29:19.665100Z"
    }
   },
   "id": "76b93b18db24b541"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot iterate over a scalar tensor.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[28], line 7\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcollections\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Counter\n\u001B[1;32m      5\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mpreprocessing\u001B[38;5;241m.\u001B[39mtext\u001B[38;5;241m.\u001B[39mTokenizer()\n\u001B[0;32m----> 7\u001B[0m \u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_on_texts\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43miter\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mds_raw_train\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/tensorflow_env/lib/python3.10/site-packages/keras/preprocessing/text.py:282\u001B[0m, in \u001B[0;36mTokenizer.fit_on_texts\u001B[0;34m(self, texts)\u001B[0m\n\u001B[1;32m    269\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit_on_texts\u001B[39m(\u001B[38;5;28mself\u001B[39m, texts):\n\u001B[1;32m    270\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Updates internal vocabulary based on a list of texts.\u001B[39;00m\n\u001B[1;32m    271\u001B[0m \n\u001B[1;32m    272\u001B[0m \u001B[38;5;124;03m    In the case where texts contains lists,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    280\u001B[0m \u001B[38;5;124;03m            or a list of list of strings.\u001B[39;00m\n\u001B[1;32m    281\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 282\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m text \u001B[38;5;129;01min\u001B[39;00m texts:\n\u001B[1;32m    283\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdocument_count \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    284\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchar_level \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(text, \u001B[38;5;28mlist\u001B[39m):\n",
      "File \u001B[0;32m~/miniconda3/envs/tensorflow_env/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:585\u001B[0m, in \u001B[0;36mTensor.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    583\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot iterate over a tensor with unknown shape.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    584\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m shape:\n\u001B[0;32m--> 585\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot iterate over a scalar tensor.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    586\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m shape[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    587\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m    588\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot iterate over a tensor with unknown first dimension.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mTypeError\u001B[0m: Cannot iterate over a scalar tensor."
     ]
    }
   ],
   "source": [
    "# Step 2: find unique tokens (words)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(next(iter(ds_raw_train))[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T06:44:25.447371Z",
     "start_time": "2023-08-01T06:44:25.268678Z"
    }
   },
   "id": "80587a9c8891cb90"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2d33b07fbc7286fc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
