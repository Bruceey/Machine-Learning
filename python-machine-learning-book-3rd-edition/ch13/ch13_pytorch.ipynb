{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Chapter 13: Going Deeper -- the Mechanics of PyTorch (Part 3/3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Higher-level PyTorch APIs: a short introduction to PyTorch-Ignite"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setting up the PyTorch model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n",
      "torch.cuda.is_available() = True\n",
      "torch.cuda.device_count()=1\n",
      "torch.cuda.get_device_name(0)=NVIDIA GeForce GTX 1660 Ti\n",
      "torch.cuda.current_device()=0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "print(torch.__version__)\n",
    "print('torch.cuda.is_available() = {}'.format(torch.cuda.is_available()))\n",
    "print(\"torch.cuda.device_count()={}\".format(torch.cuda.device_count()))\n",
    "print(\"torch.cuda.get_device_name(0)={}\".format(torch.cuda.get_device_name(0)))\n",
    "print(\"torch.cuda.current_device()={}\".format(torch.cuda.current_device()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T15:29:15.690889800Z",
     "start_time": "2023-07-27T15:29:07.987585500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "import matplotlib.pyplot\n",
    "import seaborn\n",
    "import sklearnex"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T15:31:41.719846900Z",
     "start_time": "2023-07-27T15:31:37.299985600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "image_path = './'\n",
    "torch.manual_seed(1)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "mnist_train_dataset = MNIST(\n",
    "    root=image_path,\n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "mnist_val_dataset = MNIST(\n",
    "    root=image_path,\n",
    "    train=False,\n",
    "    transform=transform,\n",
    "    download=False\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(\n",
    "    mnist_train_dataset, batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    mnist_val_dataset, batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "def get_model(image_shape=(1, 28, 28), hidden_units=(32, 16)):\n",
    "    input_size = image_shape[0] * image_shape[1] * image_shape[2]\n",
    "    all_layers = [nn.Flatten()]\n",
    "    for hidden_unit in hidden_units:\n",
    "        layer = nn.Linear(input_size, hidden_unit)\n",
    "        all_layers.append(layer)\n",
    "        all_layers.append(nn.ReLU())\n",
    "        input_size = hidden_unit\n",
    "\n",
    "    all_layers.append(nn.Linear(hidden_units[-1], 10))\n",
    "    all_layers.append(nn.Softmax(dim=1))\n",
    "    model = nn.Sequential(*all_layers)\n",
    "    return model\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = get_model().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T05:00:35.966429400Z",
     "start_time": "2023-07-18T05:00:33.716436200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setting up training and validation engines with PyTorch-Ignite"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "\n",
    "trainer = create_supervised_trainer(model, optimizer, loss_fn, device=device)\n",
    "\n",
    "val_metrics = {\n",
    "    \"accuracy\": Accuracy(),\n",
    "    \"loss\": Loss(loss_fn)\n",
    "}\n",
    "\n",
    "evaluator = create_supervised_evaluator(model, val_metrics, device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T05:19:44.437303900Z",
     "start_time": "2023-07-18T05:19:44.287146400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating event handlers for logging and validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# How many batches to wait before logging training status\n",
    "log_interval = 100\n",
    "\n",
    "@trainer.on(Events.ITERATION_COMPLETED(every=log_interval))\n",
    "def log_training_loss():\n",
    "    e = trainer.state.epoch\n",
    "    max_e = trainer.state.max_epochs\n",
    "    i = trainer.state.iteration\n",
    "    batch_loss = trainer.state.output\n",
    "    print(f\"Epoch[{e}/{max_e}], Iter[{i}] Loss: {batch_loss:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T05:22:47.928531500Z",
     "start_time": "2023-07-18T05:22:47.867695800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results():\n",
    "    eval_state = evaluator.run(val_loader)\n",
    "    metrics = eval_state.metrics\n",
    "    e = trainer.state.epoch\n",
    "    max_e = trainer.state.max_epochs\n",
    "    acc = metrics['accuracy']\n",
    "    avg_loss = metrics['loss']\n",
    "    print(f\"Validation Results - Epoch[{e}/{max_e}] Avg Accuracy: {acc:.2f} Avg Loss: {avg_loss:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T05:25:02.013887400Z",
     "start_time": "2023-07-18T05:25:01.956906800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setting up training checkpoints and saving the best model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<ignite.engine.events.RemovableEventHandle at 0x1d121352348>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ignite.handlers import Checkpoint, DiskSaver\n",
    "\n",
    "# We will save in the checkpoints the following:\n",
    "to_save = {\"model\": model, \"optimizer\": optimizer, \"trainer\": trainer}\n",
    "\n",
    "# We will save checkpoints to local disk\n",
    "output_path = \"./output\"\n",
    "save_handler = DiskSaver(dirname=output_path, require_empty=False)\n",
    "\n",
    "# Set up the handler\n",
    "checkpoint_handler = Checkpoint(to_save, save_handler, filename_prefix=\"training\")\n",
    "\n",
    "# Attach the handler to the trainer\n",
    "trainer.add_event_handler(Events.EPOCH_COMPLETED, checkpoint_handler)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T05:32:24.171997500Z",
     "start_time": "2023-07-18T05:32:24.097963800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<ignite.engine.events.RemovableEventHandle at 0x1d1219f16c8>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store best model by validation accuracy\n",
    "best_model_handler = Checkpoint(\n",
    "    {\"model\": model},\n",
    "    save_handler,\n",
    "    filename_prefix=\"best\",\n",
    "    n_saved=1,\n",
    "    score_name=\"accuracy\",\n",
    "    score_function=Checkpoint.get_default_score_fn(\"accuracy\")\n",
    ")\n",
    "\n",
    "evaluator.add_event_handler(Events.COMPLETED, best_model_handler)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T05:37:32.501479400Z",
     "start_time": "2023-07-18T05:37:32.440944400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setting up TensorBoard as an experiment tracking system"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<ignite.engine.events.RemovableEventHandle at 0x1d189f5a448>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ignite.contrib.handlers import TensorboardLogger, global_step_from_engine\n",
    "\n",
    "tb_logger = TensorboardLogger(log_dir=output_path)\n",
    "\n",
    "# Attach handler to plot trainer's loss every 100 iterations\n",
    "tb_logger.attach_output_handler(\n",
    "    trainer,\n",
    "    event_name=Events.ITERATION_COMPLETED(every=100),\n",
    "    tag=\"training\",\n",
    "    output_transform=lambda loss: {\"batch_loss\": loss},\n",
    ")\n",
    "\n",
    "# Attach handler for plotting both evaluators' metrics after every epoch completes\n",
    "tb_logger.attach_output_handler(\n",
    "    evaluator,\n",
    "    event_name=Events.EPOCH_COMPLETED,\n",
    "    tag=\"validation\",\n",
    "    metric_names=\"all\",\n",
    "    global_step_transform=global_step_from_engine(trainer),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T05:42:26.733498600Z",
     "start_time": "2023-07-18T05:42:24.221926100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Executing the PyTorch-Ignite model training code"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/5], Iter[100] Loss: 1.87\n",
      "Epoch[1/5], Iter[200] Loss: 1.82\n",
      "Epoch[1/5], Iter[300] Loss: 1.67\n",
      "Epoch[1/5], Iter[400] Loss: 1.55\n",
      "Epoch[1/5], Iter[500] Loss: 1.65\n",
      "Epoch[1/5], Iter[600] Loss: 1.59\n",
      "Epoch[1/5], Iter[700] Loss: 1.59\n",
      "Epoch[1/5], Iter[800] Loss: 1.56\n",
      "Epoch[1/5], Iter[900] Loss: 1.63\n",
      "Validation Results - Epoch[1/5] Avg Accuracy: 0.91 Avg Loss: 1.56\n",
      "Epoch[2/5], Iter[1000] Loss: 1.61\n",
      "Epoch[2/5], Iter[1100] Loss: 1.56\n",
      "Epoch[2/5], Iter[1200] Loss: 1.54\n",
      "Epoch[2/5], Iter[1300] Loss: 1.54\n",
      "Epoch[2/5], Iter[1400] Loss: 1.51\n",
      "Epoch[2/5], Iter[1500] Loss: 1.53\n",
      "Epoch[2/5], Iter[1600] Loss: 1.50\n",
      "Epoch[2/5], Iter[1700] Loss: 1.50\n",
      "Epoch[2/5], Iter[1800] Loss: 1.52\n",
      "Validation Results - Epoch[2/5] Avg Accuracy: 0.92 Avg Loss: 1.54\n",
      "Epoch[3/5], Iter[1900] Loss: 1.61\n",
      "Epoch[3/5], Iter[2000] Loss: 1.60\n",
      "Epoch[3/5], Iter[2100] Loss: 1.54\n",
      "Epoch[3/5], Iter[2200] Loss: 1.51\n",
      "Epoch[3/5], Iter[2300] Loss: 1.48\n",
      "Epoch[3/5], Iter[2400] Loss: 1.56\n",
      "Epoch[3/5], Iter[2500] Loss: 1.57\n",
      "Epoch[3/5], Iter[2600] Loss: 1.52\n",
      "Epoch[3/5], Iter[2700] Loss: 1.54\n",
      "Epoch[3/5], Iter[2800] Loss: 1.54\n",
      "Validation Results - Epoch[3/5] Avg Accuracy: 0.93 Avg Loss: 1.53\n",
      "Epoch[4/5], Iter[2900] Loss: 1.53\n",
      "Epoch[4/5], Iter[3000] Loss: 1.49\n",
      "Epoch[4/5], Iter[3100] Loss: 1.51\n",
      "Epoch[4/5], Iter[3200] Loss: 1.51\n",
      "Epoch[4/5], Iter[3300] Loss: 1.54\n",
      "Epoch[4/5], Iter[3400] Loss: 1.50\n",
      "Epoch[4/5], Iter[3500] Loss: 1.58\n",
      "Epoch[4/5], Iter[3600] Loss: 1.59\n",
      "Epoch[4/5], Iter[3700] Loss: 1.50\n",
      "Validation Results - Epoch[4/5] Avg Accuracy: 0.94 Avg Loss: 1.53\n",
      "Epoch[5/5], Iter[3800] Loss: 1.52\n",
      "Epoch[5/5], Iter[3900] Loss: 1.60\n",
      "Epoch[5/5], Iter[4000] Loss: 1.50\n",
      "Epoch[5/5], Iter[4100] Loss: 1.50\n",
      "Epoch[5/5], Iter[4200] Loss: 1.51\n",
      "Epoch[5/5], Iter[4300] Loss: 1.57\n",
      "Epoch[5/5], Iter[4400] Loss: 1.56\n",
      "Epoch[5/5], Iter[4500] Loss: 1.55\n",
      "Epoch[5/5], Iter[4600] Loss: 1.50\n",
      "Validation Results - Epoch[5/5] Avg Accuracy: 0.94 Avg Loss: 1.52\n"
     ]
    },
    {
     "data": {
      "text/plain": "State:\n\titeration: 4690\n\tepoch: 5\n\tepoch_length: 938\n\tmax_epochs: 5\n\toutput: 1.5042392015457153\n\tbatch: <class 'list'>\n\tmetrics: <class 'dict'>\n\tdataloader: <class 'torch.utils.data.dataloader.DataLoader'>\n\tseed: <class 'NoneType'>\n\ttimes: <class 'dict'>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.run(train_loader, max_epochs=5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T05:44:11.281474700Z",
     "start_time": "2023-07-18T05:43:20.083710900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
